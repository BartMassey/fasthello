# IO Buffering performance in Rust
Bart Massey

This code is originally by `/u/bruce3434` on this Reddit
[thread](https://www.reddit.com/r/rust/comments/dogxk8/why_does_buffering_the_already_buffered_stdout/). The
fundamental issue was that dropping a `BufWriter` on top of
`StdoutLocked` sped the code up by a factor of 2× even
though the writes contained no newlines. This Reddit
[comment](https://www.reddit.com/r/rust/comments/dogxk8/why_does_buffering_the_already_buffered_stdout/f5oxnlg?utm_source=share&utm_medium=web2x)
explains what is going on; this codebase is the underlying
code being measured.

* `glacial.rs` uses unlocked `Stdout`. This is pretty slow
  due to all the locking.

* `slow.rs` uses `StdoutLocked`. This is still pretty slow,
  for reasons explained in the comment above.

* `fast.rs` uses a `BufWriter` atop `StdoutLocked`. This is
  the version that is 2× faster than the slow version.

* `speedy.rs` uses a `BufWriter` atop a raw UNIX `File`. It
  is about 10% faster than the fast version, but is portable
  only to UNIX systems and has an `unsafe` in it.

* `turbo.rs` is a fairly straightforward port of `turbo.c`,
  which avoids standard library routines for things in favor
  of hand-calculation. `turbo.rs` is about 60% faster than
  `speedy.rs`.
  
* `turbo.cpp` is another port of `turbo.c` contributed by
  Hossain Adnan. It's comparable in performance, depending
  on whether you use `gcc` / `clang` / `g++` / `clang++`.

* `vecbuf.rs` uses a manual buffer currently backed by 
  `std::Vec::<u8>`. Uses POSIX write to print to STDOUT.

* `mappy.rs` is a work-in-progress attempt to use
  memory-mapped I/O. It doesn't run yet.


## Perfomance comparison

Using [hyperfine](https://github.com/sharkdp/hyperfine), run
the executables generated by clang in the root directory and
the ones in `target/release/`. 

### Example

```
 % hyperfine --warmup 2  ./turbo-c ./turbo-cpp ./target/release/vecbuf ./target/release/turbo ./target/release/fast ./target/release/glacial ./target/release/slow ./target/release/speedy
Benchmark #1: ./turbo-c
  Time (mean ± σ):     710.9 ms ±   7.7 ms    [User: 693.7 ms, System: 16.7 ms]
  Range (min … max):   698.5 ms … 720.7 ms    10 runs
 
Benchmark #2: ./turbo-cpp
  Time (mean ± σ):     850.5 ms ±   5.2 ms    [User: 831.5 ms, System: 18.5 ms]
  Range (min … max):   844.8 ms … 862.4 ms    10 runs
 
Benchmark #3: ./target/release/vecbuf
  Time (mean ± σ):     991.0 ms ±   4.8 ms    [User: 973.2 ms, System: 17.3 ms]
  Range (min … max):   984.0 ms … 998.2 ms    10 runs
 
Benchmark #4: ./target/release/turbo
  Time (mean ± σ):      1.273 s ±  0.007 s    [User: 1.256 s, System: 0.016 s]
  Range (min … max):    1.262 s …  1.283 s    10 runs
 
Benchmark #5: ./target/release/fast
  Time (mean ± σ):      2.305 s ±  0.080 s    [User: 2.297 s, System: 0.007 s]
  Range (min … max):    2.261 s …  2.486 s    10 runs
 
  Warning: Statistical outliers were detected. Consider re-running this benchmark on a quiet PC without any interferences from other programs. It might help to use the '--warmup' or '--prepare' options.
 
Benchmark #6: ./target/release/glacial
  Time (mean ± σ):      9.074 s ±  0.166 s    [User: 8.923 s, System: 0.148 s]
  Range (min … max):    8.789 s …  9.346 s    10 runs
 
Benchmark #7: ./target/release/slow
  Time (mean ± σ):      5.450 s ±  0.035 s    [User: 5.313 s, System: 0.135 s]
  Range (min … max):    5.369 s …  5.484 s    10 runs
 
Benchmark #8: ./target/release/speedy
  Time (mean ± σ):      2.394 s ±  0.033 s    [User: 2.386 s, System: 0.007 s]
  Range (min … max):    2.362 s …  2.452 s    10 runs
 
Summary
  './turbo-c' ran
    1.20 ± 0.01 times faster than './turbo-cpp'
    1.39 ± 0.02 times faster than './target/release/vecbuf'
    1.79 ± 0.02 times faster than './target/release/turbo'
    3.24 ± 0.12 times faster than './target/release/fast'
    3.37 ± 0.06 times faster than './target/release/speedy'
    7.67 ± 0.10 times faster than './target/release/slow'
   12.76 ± 0.27 times faster than './target/release/glacial'
```